{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPCA for fMRI - Matlab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data\n",
    "### https://github.com/rzlim08/CPCA_Example\n",
    "\n",
    "If you have git\n",
    "\n",
    "git clone https://github.com/rzlim08/CPCA_Example\n",
    "\n",
    "if not, you can download the zip file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and Dependencies\n",
    "\n",
    "First add the packages that we'll need. I'll try to use as few dependencies as possible here. The only thing we should need in matlab is spm for its reading functions (spm_vol, spm_read_vols). Later releases of matlab have built-in functions for this. Jimmy Shen's toolbox also is a good option https://www.mathworks.com/matlabcentral/fileexchange/8797-tools-for-nifti-and-analyze-image\n",
    "\n",
    "\n",
    "#### Dependencies\n",
    "\n",
    "Jupyter Notebook \n",
    "\n",
    "Matlab \n",
    "\n",
    "imatlab kernel\n",
    "\n",
    "spm12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "% Change this path to point to your SPM\n",
    "addpath(genpath([pwd filesep 'dependencies']));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data\n",
    "We'll also need to the data, so make sure we have a reference to that too. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the Matlab 'dir' function to read in all the images. The \\*.img string reads in all the files that end in '.img'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "scans = \n",
      "\n",
      "  214×1 struct array with fields:\n",
      "\n",
      "    name\n",
      "    folder\n",
      "    date\n",
      "    bytes\n",
      "    isdir\n",
      "    datenum\n",
      "\n"
     ]
    }
   ],
   "source": [
    "% Change this path to point to your data\n",
    "data_path = [pwd filesep 'example_data_Single_Subject'  filesep 'example_data_Single_Subject'];\n",
    "image_path = [data_path filesep 's01'];\n",
    "scans = dir([image_path filesep '*.img'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there are 214 scans for this subject. We now want to get a reference to all the images and store them in a way that matlab can read. We'll use the SPM functions 'spm_vol' and 'spm_read_vols' to read the headers and images respectively. So we will read a single scan in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ss_hdr = \n",
      "\n",
      "  struct with fields:\n",
      "\n",
      "           hdr: [1×1 struct]\n",
      "      filetype: 0\n",
      "    fileprefix: '/home/rzlim08/CPCA_Example/example_data_Single_Subject/example_data_Single_Subject/s01/fsnruna_F001'\n",
      "       machine: 'ieee-le'\n",
      "           img: [40×48×34 int16]\n",
      "      original: [1×1 struct]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scan = scans(1);\n",
    "ss_path = [scan.folder filesep scan.name]; % Older versions of matlab won't have scan.folder, use image_path instead\n",
    "ss_hdr = load_nii(ss_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_img = ss_hdr.img;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imatlab_export_fig('print-png')\n",
    "imagesc(squeeze(ss_img(:,:,17)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we have one image loaded in, we'll need to load all the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_scans = {};\n",
    "for i = 1:size(scans)\n",
    "    path_to_scans{end+1} = [scans(i).folder filesep scans(i).name];\n",
    "end\n",
    "% create a cell array of a path to each scan\n",
    "path_to_scans = path_to_scans';\n",
    "% read in scan headers\n",
    "scan_hdr = cellfun(@load_nii, path_to_scans, 'UniformOutput', 0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have a cell array storing the spm headers for all the images. We want to read those in and append them together to form a 2 dimensional matrix. We can use Matlab's cellfun for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " read_and_reshape = @(im_hdr)(double(reshape(im_hdr.img, 1,[])));\n",
    " im_cell = cellfun(read_and_reshape, scan_hdr, 'UniformOutput', 0);\n",
    " brain_scans = cell2mat(im_cell);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ans =\n",
      "\n",
      "         214       65280\n",
      "\n"
     ]
    }
   ],
   "source": [
    "size(brain_scans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are infinite ways of creating an image mask. An mask is an image of zeros and ones that denote the areas to be analyzed. We will use a precreated mask for the purpose of this analysis, but we can easily make our own masking function. For example, we can create a mask by thresholding the scans at the global mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "global_mean =\n",
      "\n",
      "   5.8343e+03\n",
      "\n"
     ]
    }
   ],
   "source": [
    "global_mean = mean(mean(brain_scans))\n",
    "thresholded = brain_scans>global_mean;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference to non-existent field 'dim'.\n"
     ]
    }
   ],
   "source": [
    "% for each voxel, if every scan is above the global mean, include the voxel in the analysis\n",
    "mask_test = floor(sum(thresholded)/size(brain_scans,1)); \n",
    "m = reshape(mask_test, ss_hdr.dim);\n",
    "imagesc(m(:,:,17))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ans =\n",
      "\n",
      "         214       29401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "% find where all scans are one, and take those out of the brain scans\n",
    "masked_im = brain_scans(:, find(mask_test));\n",
    "size(masked_im)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this workshop, we'll use a precreated mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "% read in and flatten mask\n",
    "mask = read_and_reshape(load_nii([data_path filesep 'mask.img']));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get our data matrix, we will select only the voxels that we've included in our analysis. We call our data matrix Z. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ans =\n",
      "\n",
      "         214       29151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Z = brain_scans(:, find(mask));\n",
    "size(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will want to standardize this matrix. PCA should be mean centered at the very least to return meaningful results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = zscore(Z, 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ans =\n",
      "\n",
      "  logical\n",
      "\n",
      "   1\n",
      "\n",
      "\n",
      "ans =\n",
      "\n",
      "  logical\n",
      "\n",
      "   1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all(abs(mean(Z))<0.01)\n",
    "all(abs(std(Z)-1)<0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a standardized data matrix. We will now create a design matrix to represent the timing information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Design Matrix (G Matrix)\n",
    "\n",
    "Since we want to get the neural responses to the task, we want to constain our analysis to the scans where we expect to see these responses. We create our design matrix by inserting ones into the places where we expect to see signals. This is a similar procedure to that used in SPM's first level analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Letters2=[55.269 79.074 89.123 118.569 123.266 138.011 163.450 179.190 189.245];\n",
    "Letters4=[5.025 10.383 20.765 69.681 74.377 108.515 132.986 158.425 199.293];\n",
    "Letters6=[15.740 25.789 40.540 143.369 148.727 168.808 173.832 183.887 194.269];\n",
    "Letters8=[30.486 35.844 45.237 59.960 64.656 84.098 94.481 113.211 128.290];\n",
    "onsets = {Letters2; Letters4; Letters6; Letters8};\n",
    "onsets = cellfun(@ceil, onsets, 'UniformOutput', 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "conditions =\n",
      "\n",
      "     4\n",
      "\n",
      "\n",
      "bins =\n",
      "\n",
      "     8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conditions = size(onsets,1)\n",
    "bins = 8\n",
    "G = zeros(size(Z,1), bins*conditions);\n",
    "% For each condition\n",
    "for j = 1:conditions\n",
    "    cond_onsets = onsets{j};\n",
    "    % For each onset\n",
    "    for i = 1:size(cond_onsets,2)\n",
    "        % Take the scan at the time of the onset, and the next 7 scans after, insert ones into these scans\n",
    "        G(cond_onsets(i):cond_onsets(i)+bins-1, ...\n",
    "            (j-1)*bins+1:(j-1)*bins+bins) = ...\n",
    "            G(cond_onsets(i):cond_onsets(i)+bins-1, ...\n",
    "            (j-1)*bins+1:(j-1)*bins+bins)|...\n",
    "            eye(bins);\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%a = calculate_hrf_shape([Letters2' ones(9, 1)*10], 214, 3);\n",
    "%b = calculate_hrf_shape([Letters4' ones(9, 1)*10], 214, 3);\n",
    "%c = calculate_hrf_shape([Letters6' ones(9, 1)*10], 214, 3);\n",
    "%d = calculate_hrf_shape([Letters8' ones(9, 1)*10], 214, 3);\n",
    "%plot([a b c])\n",
    "%title('HRF shape estimation for design')\n",
    "%xlabel('scans')\n",
    "%ylabel('hrf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a design matrix for each of the different conditions and onsets. Finally, we want to standardize the G matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = zscore(G,1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "We will then regress the Z matrix onto the G matrix. This will give use the betas for the regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "% This uses Matlab's mldivide function. \n",
    "% We can also use the normal equations, which seem to work faster in Matlab 2016a\n",
    "C = G\\Z;  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD/PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can do the singular value decomposition (SVD). SVD is a matrix decomposition technique that will yield equivalent results to PCA. Normally, with multiple participants we'd have to append all the matrices from each participant together, but here we only have a single participant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank of Z = 213\n",
      "rank of GC = 32\n"
     ]
    }
   ],
   "source": [
    "disp(['rank of Z = ', num2str(rank(Z))])\n",
    "disp(['rank of GC = ' num2str(rank(G*C))]) % The rank of GC is equal to the rank of G. Thus we can see this as projecting Z onto a lower dimensional space\n",
    "[U D V] = svds(G*C, 3);\n",
    "% Create predictor weights by regressing the eigenvectors onto the design matrix and multiplying by the sqrt of \n",
    "% the number of scans\n",
    "P = (G\\U)*sqrt(size(G,1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make very disappointing plots of the predictor weights, since we only have one participant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "p_conds =\n",
      "\n",
      "    0.0944    0.1965    0.1043    0.4236\n",
      "    0.0498    0.2173    0.1596    0.5147\n",
      "   -0.1060    0.1634    0.1738    0.5364\n",
      "   -0.1459    0.0781    0.0162    0.4167\n",
      "   -0.1484    0.1052   -0.0566    0.3124\n",
      "   -0.2330    0.0993   -0.1557    0.1809\n",
      "   -0.3077    0.0712   -0.2642    0.0701\n",
      "   -0.2699    0.0511   -0.2952    0.0499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p_conds = reshape(P(:, 1), [8, 4])\n",
    "plot(p_conds)\n",
    "xlabel('time bin')\n",
    "ylabel('predictor weight')\n",
    "legend('2 Letter','4 Letter', '6 Letter', '8 Letter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "p_conds =\n",
      "\n",
      "    0.2589    0.2665    0.2923   -0.0022\n",
      "    0.1458    0.2286    0.2975    0.1674\n",
      "   -0.0763    0.1315    0.3807    0.2003\n",
      "   -0.2921   -0.0916    0.1656   -0.0142\n",
      "   -0.1667   -0.0651    0.0252   -0.1912\n",
      "   -0.0225    0.0846    0.0813   -0.2596\n",
      "   -0.1877    0.0239   -0.1760   -0.5019\n",
      "   -0.1095   -0.0432   -0.2043   -0.4999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p_conds = reshape(P(:, 2), [8, 4])\n",
    "plot(p_conds)\n",
    "xlabel('time bin')\n",
    "ylabel('predictor weight')\n",
    "legend('2 Letter','4 Letter', '6 Letter', '8 Letter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "p_conds =\n",
      "\n",
      "   -0.0464   -0.0710    0.0393   -0.1134\n",
      "    0.0849   -0.0204   -0.0071   -0.0779\n",
      "    0.2258    0.1136    0.2737    0.2782\n",
      "    0.2452    0.2245    0.6223    0.6385\n",
      "    0.2973    0.2554    0.5577    0.5508\n",
      "    0.3401    0.1753    0.4631    0.3573\n",
      "    0.3488    0.1503    0.3875    0.2267\n",
      "    0.2697    0.1311    0.2820    0.1149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p_conds = reshape(P(:, 3), [8, 4])\n",
    "plot(p_conds)\n",
    "xlabel('time bin')\n",
    "ylabel('predictor weight')\n",
    "legend('2 Letter','4 Letter', '6 Letter', '8 Letter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the Impact of Analysis Software on Task fMRI Results\n",
    "\n",
    " https://doi.org/10.1101/285585"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MATLAB",
   "language": "matlab",
   "name": "imatlab"
  },
  "language_info": {
   "codemirror_mode": "octave",
   "file_extension": ".m",
   "mimetype": "text/x-matlab",
   "name": "matlab",
   "nbconvert_exporter": "imatlab._exporter.MatlabExporter",
   "pygments_lexer": "matlab",
   "version": "9.2.0.556344 (R2017a)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
